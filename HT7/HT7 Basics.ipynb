{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "focused-express",
   "metadata": {},
   "source": [
    "## Tensorflow v 1.15\n",
    "### Basic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "printable-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "stretch-security",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow._api.v1.version' from 'C:\\\\Users\\\\user\\\\Anaconda3\\\\envs\\\\old python\\\\lib\\\\site-packages\\\\tensorflow_core\\\\_api\\\\v1\\\\version\\\\__init__.py'>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-forum",
   "metadata": {},
   "source": [
    "## Titanic dataset\n",
    "\n",
    "Datasets EDA are in the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "specified-virginia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "...            ...    ...               ...      ...   ...      ...  \n",
       "887              0      0            211536  13.0000   NaN        S  \n",
       "888              0      0            112053  30.0000   B42        S  \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890              0      0            111369  30.0000  C148        C  \n",
       "891              0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Titanic.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "thermal-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Name', 'Ticket', \"Cabin\", 'Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-brain",
   "metadata": {},
   "source": [
    "#### Titanic dataset columns\n",
    "\n",
    "- Survived (TARGET): Flag, true if passanger survived accident\n",
    "- PClass: 1 for 1st class, 2 for 2nd, 3 for 3rd (cat feature)\n",
    "- Sex (cat feature)\n",
    "- Age\n",
    "- SibSp amount of siblings on the board\n",
    "- Parch amount of parents/children on the board\n",
    "- Fare \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "hazardous-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch     Fare\n",
       "PassengerId                                                       \n",
       "1                   0       3    male  22.0      1      0   7.2500\n",
       "2                   1       1  female  38.0      1      0  71.2833\n",
       "3                   1       3  female  26.0      0      0   7.9250\n",
       "4                   1       1  female  35.0      1      0  53.1000\n",
       "5                   0       3    male  35.0      0      0   8.0500\n",
       "...               ...     ...     ...   ...    ...    ...      ...\n",
       "887                 0       2    male  27.0      0      0  13.0000\n",
       "888                 1       1  female  19.0      0      0  30.0000\n",
       "889                 0       3  female   NaN      1      2  23.4500\n",
       "890                 1       1    male  26.0      0      0  30.0000\n",
       "891                 0       3    male  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "raised-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_cols = ['Pclass', 'Sex']\n",
    "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "y = data['Survived']\n",
    "X = data.drop('Survived', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "healthy-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()),\n",
    "    \n",
    "])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers =[\n",
    "    ('num', num_trans, num_cols),\n",
    "    ('cat', cat_trans, cat_cols),\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "seven-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "vulnerable-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_train['Not'] = y_train['Survived'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "terminal-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test['Not'] = y_test['Survived'] == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-tuner",
   "metadata": {},
   "source": [
    "#### Softmax regression for classification for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "adjustable-dayton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 12.875968138376871\n",
      "Average loss epoch 1: 11.363237599531809\n",
      "Average loss epoch 2: 10.066785037517548\n",
      "Average loss epoch 3: 8.808952490488688\n",
      "Average loss epoch 4: 7.530684947967529\n",
      "Average loss epoch 5: 6.23762987057368\n",
      "Average loss epoch 6: 4.94433789451917\n",
      "Average loss epoch 7: 3.6659236947695413\n",
      "Average loss epoch 8: 2.4464094837506614\n",
      "Average loss epoch 9: 1.4588999350865681\n",
      "Average loss epoch 10: 0.9650745391845703\n",
      "Average loss epoch 11: 0.9343263804912567\n",
      "Average loss epoch 12: 0.8715998604893684\n",
      "Average loss epoch 13: 0.8115653470158577\n",
      "Average loss epoch 14: 0.770466518898805\n",
      "Average loss epoch 15: 0.7383232489228249\n",
      "Average loss epoch 16: 0.7103373085459074\n",
      "Average loss epoch 17: 0.6828954343994459\n",
      "Average loss epoch 18: 0.6587137654423714\n",
      "Average loss epoch 19: 0.6372869039575259\n",
      "Average loss epoch 20: 0.6180267756183943\n",
      "Average loss epoch 21: 0.6005582759777705\n",
      "Average loss epoch 22: 0.5847223202387491\n",
      "Average loss epoch 23: 0.5704403867324194\n",
      "Average loss epoch 24: 0.5575312003493309\n",
      "Average loss epoch 25: 0.5458686749140421\n",
      "Average loss epoch 26: 0.5353925401965777\n",
      "Average loss epoch 27: 0.5260360886653265\n",
      "Average loss epoch 28: 0.5177350466450056\n",
      "Average loss epoch 29: 0.5104336614410082\n",
      "Accuracy 0.8133333333333334\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 30\n",
    "batch_size = 50\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, X_train.shape[1]], name='data') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, 2], name='label')\n",
    "\n",
    "\n",
    "w = tf.get_variable(name='weights',shape=(X_train.shape[1], num_classes), initializer=tf.random_normal_initializer(), )\n",
    "b = tf.get_variable(name = 'bias', shape=(1, num_classes), initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "logits = tf.matmul(X, w) + b \n",
    "\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "        n_batches = X_train.shape[0] // batch_size\n",
    "        for j in range(n_batches-1):\n",
    "            X_batch, y_batch = X_train.iloc[j*batch_size:(j+1)*batch_size], y_train.iloc[j*batch_size:(j+1)*batch_size]\n",
    "            _, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y: y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/(n_batches-1)))\n",
    "\n",
    "\n",
    "    total_correct_preds = 0\n",
    "    n_batches = X_test.shape[0] // batch_size\n",
    "    for j in range(n_batches - 1):\n",
    "        X_batch, Y_batch = X_test.iloc[j*batch_size:(j+1)*batch_size], y_test.iloc[j*batch_size:(j+1)*batch_size]\n",
    "        accuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n",
    "        total_correct_preds += accuracy_batch  \n",
    "    print('Accuracy {0}'.format(total_correct_preds/((n_batches - 1) * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "artistic-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_X_train, titanic_y_train, titanic_X_test, titanic_y_test = X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-reverse",
   "metadata": {},
   "source": [
    "### Thyroid Disease dataset\n",
    "\n",
    "EDA and preprocessing are taken from HT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "billion-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_57_hypothyroid.csv')\n",
    "data = data.drop(['TBG_measured','TBG'], axis=1)\n",
    "for i in ['TSH','T3','TT4','FTI','T4U']:\n",
    "    data[i] = data[i].apply(lambda x: 0 if x == '?' else x)\n",
    "data['sex'] = data['sex'].apply(lambda x: 'U' if x == '?' else x) \n",
    "data['age'] = data['age'].replace('?', np.median(pd.to_numeric(data.query('sex == \"U\" and age != \"?\"')['age']) ))\n",
    "num_cols = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "connected-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = [col for col in data.columns if data[col].nunique() == 2 and data[col][0] in ['t', 'f']]\n",
    "for col in bool_cols:\n",
    "    data[col] = data[col] == 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "color-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('hypopituitary', axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "sporting-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Class'\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "broken-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[TARGET] != 'secondary_hypothyroid']\n",
    "X = data.drop(TARGET, axis=1)\n",
    "y = data[TARGET]\n",
    "cat_cols = [col for col in X.columns if X[col].dtype =='object']\n",
    "for col in cat_cols:\n",
    "    try:\n",
    "        X[col] = pd.to_numeric(X[col])\n",
    "    except:\n",
    "        pass\n",
    "cat_cols = [col for col in X.columns if X[col].dtype =='object']\n",
    "num_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "bool_cols = [col for col in X.columns if X[col].dtype == 'bool']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# X_train[cat_cols] = X_train[cat_cols].apply(lambda x: str(x))\n",
    "# X_test[cat_cols] = X_test[cat_cols].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "married-alexandria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>referral_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>F</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>M</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3709 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex referral_source\n",
       "0      F            SVHC\n",
       "1      F           other\n",
       "2      M           other\n",
       "3      F           other\n",
       "4      F             SVI\n",
       "...   ..             ...\n",
       "3767   F           other\n",
       "3768   F             SVI\n",
       "3769   F           other\n",
       "3770   M             SVI\n",
       "3771   F           other\n",
       "\n",
       "[3709 rows x 2 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "marine-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "devoted-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',  StandardScaler())\n",
    "    \n",
    "])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "bool_trans = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers =[\n",
    "    ('num', num_trans, num_cols),\n",
    "    ('cat', cat_trans, cat_cols),\n",
    "    ('bool', bool_trans, bool_cols)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "seeing-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "prime-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.074125</td>\n",
       "      <td>-0.127238</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>0.399228</td>\n",
       "      <td>0.214244</td>\n",
       "      <td>0.466885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.220544</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>-0.399673</td>\n",
       "      <td>-0.359760</td>\n",
       "      <td>-0.507201</td>\n",
       "      <td>0.444438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.390837</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>-0.261826</td>\n",
       "      <td>0.154123</td>\n",
       "      <td>-0.094300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.390065</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>0.517520</td>\n",
       "      <td>-0.016991</td>\n",
       "      <td>0.875568</td>\n",
       "      <td>-0.341222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.390065</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.700958</td>\n",
       "      <td>-1.045298</td>\n",
       "      <td>-2.731657</td>\n",
       "      <td>-2.271699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>-0.292452</td>\n",
       "      <td>-0.146561</td>\n",
       "      <td>1.067835</td>\n",
       "      <td>0.962348</td>\n",
       "      <td>1.176170</td>\n",
       "      <td>0.197516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>0.049192</td>\n",
       "      <td>-0.156223</td>\n",
       "      <td>0.334081</td>\n",
       "      <td>-0.016991</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.219964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>1.269351</td>\n",
       "      <td>-0.030623</td>\n",
       "      <td>0.242362</td>\n",
       "      <td>0.301294</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>0.197516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>0.878900</td>\n",
       "      <td>-0.175932</td>\n",
       "      <td>0.792677</td>\n",
       "      <td>1.452018</td>\n",
       "      <td>0.605026</td>\n",
       "      <td>1.050518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>0.732481</td>\n",
       "      <td>-0.107915</td>\n",
       "      <td>-0.216235</td>\n",
       "      <td>0.374744</td>\n",
       "      <td>0.214244</td>\n",
       "      <td>0.444438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2781 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5    6    7   \\\n",
       "0     1.074125 -0.127238  0.425800  0.399228  0.214244  0.466885  0.0  1.0   \n",
       "1     1.220544  0.050534 -0.399673 -0.359760 -0.507201  0.444438  1.0  0.0   \n",
       "2     0.390837 -0.096321  0.425800 -0.261826  0.154123 -0.094300  1.0  0.0   \n",
       "3    -0.390065 -0.115644  0.517520 -0.016991  0.875568 -0.341222  0.0  1.0   \n",
       "4    -0.390065  0.038940  0.700958 -1.045298 -2.731657 -2.271699  1.0  0.0   \n",
       "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "2776 -0.292452 -0.146561  1.067835  0.962348  1.176170  0.197516  0.0  1.0   \n",
       "2777  0.049192 -0.156223  0.334081 -0.016991  0.063943  0.219964  1.0  0.0   \n",
       "2778  1.269351 -0.030623  0.242362  0.301294  0.424665  0.197516  1.0  0.0   \n",
       "2779  0.878900 -0.175932  0.792677  1.452018  0.605026  1.050518  1.0  0.0   \n",
       "2780  0.732481 -0.107915 -0.216235  0.374744  0.214244  0.444438  1.0  0.0   \n",
       "\n",
       "       8    9   ...   22   23   24   25   26   27   28   29   30   31  \n",
       "0     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2776  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2777  0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2778  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2779  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2780  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[2781 rows x 32 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "attended-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_train = pd.DataFrame()\n",
    "_y_test = pd.DataFrame()\n",
    "for j in range(pd.Series(y_train).nunique()):\n",
    "    _y_train[j] = y_train == j\n",
    "    _y_test[j] = y_test == j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "wrong-retirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2\n",
       "0    False   True  False\n",
       "1    False   True  False\n",
       "2     True  False  False\n",
       "3    False   True  False\n",
       "4    False   True  False\n",
       "..     ...    ...    ...\n",
       "923   True  False  False\n",
       "924  False   True  False\n",
       "925   True  False  False\n",
       "926  False   True  False\n",
       "927  False   True  False\n",
       "\n",
       "[928 rows x 3 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "scientific-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 1.8245101754481976\n",
      "Average loss epoch 1: 0.590573305120835\n",
      "Average loss epoch 2: 0.4009706767705771\n",
      "Average loss epoch 3: 0.3338426047792801\n",
      "Average loss epoch 4: 0.2892147468832823\n",
      "Average loss epoch 5: 0.25691771793823975\n",
      "Average loss epoch 6: 0.23684525174590257\n",
      "Average loss epoch 7: 0.22484114250311485\n",
      "Average loss epoch 8: 0.2162963143334939\n",
      "Average loss epoch 9: 0.20970032879939446\n",
      "Average loss epoch 10: 0.20435771947869888\n",
      "Average loss epoch 11: 0.19988287899356622\n",
      "Average loss epoch 12: 0.19603668812375802\n",
      "Average loss epoch 13: 0.1926637446651092\n",
      "Average loss epoch 14: 0.18965935133970702\n",
      "Average loss epoch 15: 0.18695049360394478\n",
      "Average loss epoch 16: 0.1844846448646142\n",
      "Average loss epoch 17: 0.18222283571958542\n",
      "Average loss epoch 18: 0.18013537302613258\n",
      "Average loss epoch 19: 0.1781990576822024\n",
      "Average loss epoch 20: 0.17639531682317072\n",
      "Average loss epoch 21: 0.1747090111558254\n",
      "Average loss epoch 22: 0.17312751051325065\n",
      "Average loss epoch 23: 0.17164020526867646\n",
      "Average loss epoch 24: 0.17023796358933815\n",
      "Average loss epoch 25: 0.1689129391541848\n",
      "Average loss epoch 26: 0.16765825507732537\n",
      "Average loss epoch 27: 0.16646787037069982\n",
      "Average loss epoch 28: 0.1653364484126751\n",
      "Average loss epoch 29: 0.16425925464584276\n",
      "Accuracy 0.9475\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = _y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, X_train.shape[1]], name='data') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, num_classes], name='label')\n",
    "\n",
    "\n",
    "w = tf.get_variable(name='weights',shape=(X_train.shape[1], num_classes), initializer=tf.random_normal_initializer(), )\n",
    "b = tf.get_variable(name = 'bias', shape=(1, num_classes), initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "logits = tf.matmul(X, w) + b \n",
    "\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "        n_batches = X_train.shape[0] // batch_size\n",
    "        for j in range(n_batches-1):\n",
    "            X_batch, y_batch = X_train.iloc[j*batch_size:(j+1)*batch_size], _y_train.iloc[j*batch_size:(j+1)*batch_size]\n",
    "            _, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y: y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/(n_batches-1)))\n",
    "\n",
    "\n",
    "    total_correct_preds = 0\n",
    "    n_batches = X_test.shape[0] // batch_size\n",
    "    for j in range(n_batches - 1):\n",
    "        X_batch, Y_batch = X_test.iloc[j*batch_size:(j+1)*batch_size], _y_test.iloc[j*batch_size:(j+1)*batch_size]\n",
    "        accuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n",
    "        total_correct_preds += accuracy_batch  \n",
    "    print('Accuracy {0}'.format(total_correct_preds/((n_batches - 1) * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "labeled-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_X_train, TD_y_train, TD_X_test, TD_y_test = X_train, _y_train, X_test, _y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-seattle",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "together-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-enforcement",
   "metadata": {},
   "source": [
    "### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "abandoned-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/30\n",
      "668/668 [==============================] - 0s 345us/step - loss: 15.4650 - accuracy: 0.3832 - val_loss: 16.8197 - val_accuracy: 0.3857\n",
      "Epoch 2/30\n",
      "668/668 [==============================] - 0s 43us/step - loss: 14.5461 - accuracy: 0.3832 - val_loss: 15.7871 - val_accuracy: 0.3857\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 0s 60us/step - loss: 13.5887 - accuracy: 0.3832 - val_loss: 14.7749 - val_accuracy: 0.3857\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 12.6730 - accuracy: 0.3832 - val_loss: 13.7488 - val_accuracy: 0.3857\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 0s 54us/step - loss: 11.7301 - accuracy: 0.3832 - val_loss: 12.7353 - val_accuracy: 0.3857\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 0s 55us/step - loss: 10.7837 - accuracy: 0.3832 - val_loss: 11.7342 - val_accuracy: 0.3857\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 9.8611 - accuracy: 0.3832 - val_loss: 10.7094 - val_accuracy: 0.3857\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 0s 57us/step - loss: 8.9234 - accuracy: 0.3832 - val_loss: 9.6701 - val_accuracy: 0.3857\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 0s 55us/step - loss: 7.9807 - accuracy: 0.3832 - val_loss: 8.6685 - val_accuracy: 0.3857\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 0s 60us/step - loss: 7.0743 - accuracy: 0.3832 - val_loss: 7.6493 - val_accuracy: 0.3857\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 0s 57us/step - loss: 6.1334 - accuracy: 0.3832 - val_loss: 6.6657 - val_accuracy: 0.3857\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 0s 63us/step - loss: 5.2508 - accuracy: 0.3802 - val_loss: 5.6776 - val_accuracy: 0.3857\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 0s 66us/step - loss: 4.3656 - accuracy: 0.3862 - val_loss: 4.7487 - val_accuracy: 0.3901\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 0s 66us/step - loss: 3.5568 - accuracy: 0.3967 - val_loss: 3.9052 - val_accuracy: 0.3991\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 0s 78us/step - loss: 2.8461 - accuracy: 0.4671 - val_loss: 3.2107 - val_accuracy: 0.6009\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 0s 63us/step - loss: 2.3147 - accuracy: 0.6183 - val_loss: 2.6572 - val_accuracy: 0.5874\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 0s 64us/step - loss: 1.9200 - accuracy: 0.6243 - val_loss: 2.2532 - val_accuracy: 0.6233\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 0s 54us/step - loss: 1.6369 - accuracy: 0.6437 - val_loss: 1.9602 - val_accuracy: 0.6592\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 0s 61us/step - loss: 1.4365 - accuracy: 0.6796 - val_loss: 1.7498 - val_accuracy: 0.6726\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 0s 67us/step - loss: 1.2950 - accuracy: 0.6931 - val_loss: 1.6015 - val_accuracy: 0.6816\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 0s 54us/step - loss: 1.1967 - accuracy: 0.7141 - val_loss: 1.4798 - val_accuracy: 0.6726\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 1.1224 - accuracy: 0.7246 - val_loss: 1.3832 - val_accuracy: 0.6861\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 1.0632 - accuracy: 0.7335 - val_loss: 1.3121 - val_accuracy: 0.6816\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 1.0161 - accuracy: 0.7395 - val_loss: 1.2518 - val_accuracy: 0.6682\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 0s 48us/step - loss: 0.9769 - accuracy: 0.7395 - val_loss: 1.1997 - val_accuracy: 0.6682\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.9444 - accuracy: 0.7320 - val_loss: 1.1516 - val_accuracy: 0.6682\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 0s 57us/step - loss: 0.9143 - accuracy: 0.7350 - val_loss: 1.1057 - val_accuracy: 0.6816\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 0s 58us/step - loss: 0.8841 - accuracy: 0.7335 - val_loss: 1.0647 - val_accuracy: 0.6906\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 0s 57us/step - loss: 0.8567 - accuracy: 0.7365 - val_loss: 1.0257 - val_accuracy: 0.6906\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 0s 48us/step - loss: 0.8287 - accuracy: 0.7380 - val_loss: 0.9869 - val_accuracy: 0.6861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fcffb30eb8>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(titanic_y_train.shape[1], activation='softmax', input_shape=(titanic_X_train.shape[1],)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(titanic_X_train, titanic_y_train,\n",
    "          batch_size=50, epochs=30,\n",
    "          validation_data = (titanic_X_test, titanic_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fifth-breathing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 668 samples, validate on 223 samples\n",
      "Epoch 1/30\n",
      "668/668 [==============================] - 0s 473us/step - loss: 2.5525 - accuracy: 0.6168 - val_loss: 1.9713 - val_accuracy: 0.6143\n",
      "Epoch 2/30\n",
      "668/668 [==============================] - 0s 47us/step - loss: 1.5061 - accuracy: 0.6123 - val_loss: 1.1435 - val_accuracy: 0.5830\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 0s 53us/step - loss: 0.9403 - accuracy: 0.6048 - val_loss: 0.9064 - val_accuracy: 0.6054\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 0s 51us/step - loss: 0.8105 - accuracy: 0.6287 - val_loss: 0.8600 - val_accuracy: 0.6009\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 0s 46us/step - loss: 0.7579 - accuracy: 0.6602 - val_loss: 0.8082 - val_accuracy: 0.5919\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 0s 53us/step - loss: 0.7138 - accuracy: 0.6766 - val_loss: 0.7741 - val_accuracy: 0.5919\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 0s 51us/step - loss: 0.6823 - accuracy: 0.6871 - val_loss: 0.7324 - val_accuracy: 0.6009\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 0.6565 - accuracy: 0.6886 - val_loss: 0.6942 - val_accuracy: 0.6143\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.6306 - accuracy: 0.6976 - val_loss: 0.6684 - val_accuracy: 0.6278\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 0s 48us/step - loss: 0.6157 - accuracy: 0.7111 - val_loss: 0.6428 - val_accuracy: 0.6502\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 0s 45us/step - loss: 0.5950 - accuracy: 0.7186 - val_loss: 0.6299 - val_accuracy: 0.6457\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 0.5806 - accuracy: 0.7320 - val_loss: 0.6133 - val_accuracy: 0.6637\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 0s 46us/step - loss: 0.5691 - accuracy: 0.7275 - val_loss: 0.6000 - val_accuracy: 0.6682\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.5605 - accuracy: 0.7425 - val_loss: 0.5866 - val_accuracy: 0.6951\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.5552 - accuracy: 0.7395 - val_loss: 0.5839 - val_accuracy: 0.6951\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.5454 - accuracy: 0.7650 - val_loss: 0.5723 - val_accuracy: 0.7175\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 0.5397 - accuracy: 0.7545 - val_loss: 0.5662 - val_accuracy: 0.7130\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 0s 50us/step - loss: 0.5317 - accuracy: 0.7620 - val_loss: 0.5589 - val_accuracy: 0.7265\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 0s 49us/step - loss: 0.5239 - accuracy: 0.7650 - val_loss: 0.5537 - val_accuracy: 0.7534\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 0s 44us/step - loss: 0.5214 - accuracy: 0.7620 - val_loss: 0.5452 - val_accuracy: 0.7578\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 0s 51us/step - loss: 0.5167 - accuracy: 0.7650 - val_loss: 0.5456 - val_accuracy: 0.7489\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 0s 51us/step - loss: 0.5140 - accuracy: 0.7784 - val_loss: 0.5409 - val_accuracy: 0.7623\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 0s 45us/step - loss: 0.5101 - accuracy: 0.7784 - val_loss: 0.5374 - val_accuracy: 0.7578\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 0s 52us/step - loss: 0.5070 - accuracy: 0.7740 - val_loss: 0.5362 - val_accuracy: 0.7578\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 0s 42us/step - loss: 0.5033 - accuracy: 0.7829 - val_loss: 0.5317 - val_accuracy: 0.7623\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 0s 45us/step - loss: 0.5017 - accuracy: 0.7784 - val_loss: 0.5289 - val_accuracy: 0.7623\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 0s 45us/step - loss: 0.4994 - accuracy: 0.7829 - val_loss: 0.5304 - val_accuracy: 0.7623\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 0s 48us/step - loss: 0.4980 - accuracy: 0.7844 - val_loss: 0.5262 - val_accuracy: 0.7668\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 0s 43us/step - loss: 0.4968 - accuracy: 0.7814 - val_loss: 0.5252 - val_accuracy: 0.7623\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 0s 46us/step - loss: 0.4938 - accuracy: 0.7814 - val_loss: 0.5280 - val_accuracy: 0.7623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc8203eda0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(titanic_X_train.shape[1],)))\n",
    "model.add(Dense(titanic_y_train.shape[1], activation='softmax'))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(titanic_X_train, titanic_y_train,\n",
    "          batch_size=50, epochs=30,\n",
    "          validation_data = (titanic_X_test, titanic_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-terminal",
   "metadata": {},
   "source": [
    "### Thyroid Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "civilian-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2781 samples, validate on 928 samples\n",
      "Epoch 1/20\n",
      "2781/2781 [==============================] - 0s 90us/step - loss: 1.0135 - accuracy: 0.5038 - val_loss: 0.8929 - val_accuracy: 0.6401\n",
      "Epoch 2/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.8021 - accuracy: 0.7033 - val_loss: 0.7149 - val_accuracy: 0.7468\n",
      "Epoch 3/20\n",
      "2781/2781 [==============================] - 0s 20us/step - loss: 0.6499 - accuracy: 0.7979 - val_loss: 0.5913 - val_accuracy: 0.8459\n",
      "Epoch 4/20\n",
      "2781/2781 [==============================] - 0s 22us/step - loss: 0.5455 - accuracy: 0.8749 - val_loss: 0.5072 - val_accuracy: 0.8782\n",
      "Epoch 5/20\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.4750 - accuracy: 0.8986 - val_loss: 0.4488 - val_accuracy: 0.8944\n",
      "Epoch 6/20\n",
      "2781/2781 [==============================] - 0s 20us/step - loss: 0.4257 - accuracy: 0.9108 - val_loss: 0.4093 - val_accuracy: 0.9149\n",
      "Epoch 7/20\n",
      "2781/2781 [==============================] - 0s 20us/step - loss: 0.3919 - accuracy: 0.9227 - val_loss: 0.3805 - val_accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "2781/2781 [==============================] - 0s 20us/step - loss: 0.3671 - accuracy: 0.9252 - val_loss: 0.3599 - val_accuracy: 0.9256\n",
      "Epoch 9/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.3490 - accuracy: 0.9256 - val_loss: 0.3443 - val_accuracy: 0.9256\n",
      "Epoch 10/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.3352 - accuracy: 0.9256 - val_loss: 0.3319 - val_accuracy: 0.9256\n",
      "Epoch 11/20\n",
      "2781/2781 [==============================] - 0s 17us/step - loss: 0.3241 - accuracy: 0.9256 - val_loss: 0.3222 - val_accuracy: 0.9256\n",
      "Epoch 12/20\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.3152 - accuracy: 0.9256 - val_loss: 0.3142 - val_accuracy: 0.9267\n",
      "Epoch 13/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.3077 - accuracy: 0.9263 - val_loss: 0.3073 - val_accuracy: 0.9278\n",
      "Epoch 14/20\n",
      "2781/2781 [==============================] - 0s 16us/step - loss: 0.3012 - accuracy: 0.9270 - val_loss: 0.3014 - val_accuracy: 0.9278\n",
      "Epoch 15/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.2957 - accuracy: 0.9270 - val_loss: 0.2961 - val_accuracy: 0.9278\n",
      "Epoch 16/20\n",
      "2781/2781 [==============================] - 0s 16us/step - loss: 0.2907 - accuracy: 0.9270 - val_loss: 0.2916 - val_accuracy: 0.9278\n",
      "Epoch 17/20\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.2862 - accuracy: 0.9277 - val_loss: 0.2874 - val_accuracy: 0.9289\n",
      "Epoch 18/20\n",
      "2781/2781 [==============================] - 0s 21us/step - loss: 0.2820 - accuracy: 0.9281 - val_loss: 0.2835 - val_accuracy: 0.9289\n",
      "Epoch 19/20\n",
      "2781/2781 [==============================] - 0s 21us/step - loss: 0.2782 - accuracy: 0.9281 - val_loss: 0.2799 - val_accuracy: 0.9289\n",
      "Epoch 20/20\n",
      "2781/2781 [==============================] - 0s 21us/step - loss: 0.2747 - accuracy: 0.9284 - val_loss: 0.2766 - val_accuracy: 0.9289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fcffb9ef28>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(TD_y_train.shape[1], activation='softmax', input_shape=(TD_X_train.shape[1],)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(TD_X_train, TD_y_train,\n",
    "          batch_size=100, epochs=20,\n",
    "          validation_data = (TD_X_test, TD_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-facing",
   "metadata": {},
   "source": [
    "### Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "regulation-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "boston_data = pd.DataFrame(boston.data, columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "intended-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_target = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "flush-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in boston_data.columns\n",
    "                     if boston_data[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston_data, boston_target, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "unlikely-appreciation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.074125</td>\n",
       "      <td>-0.127238</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>0.399228</td>\n",
       "      <td>0.214244</td>\n",
       "      <td>0.466885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.220544</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>-0.399673</td>\n",
       "      <td>-0.359760</td>\n",
       "      <td>-0.507201</td>\n",
       "      <td>0.444438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.390837</td>\n",
       "      <td>-0.096321</td>\n",
       "      <td>0.425800</td>\n",
       "      <td>-0.261826</td>\n",
       "      <td>0.154123</td>\n",
       "      <td>-0.094300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.390065</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>0.517520</td>\n",
       "      <td>-0.016991</td>\n",
       "      <td>0.875568</td>\n",
       "      <td>-0.341222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.390065</td>\n",
       "      <td>0.038940</td>\n",
       "      <td>0.700958</td>\n",
       "      <td>-1.045298</td>\n",
       "      <td>-2.731657</td>\n",
       "      <td>-2.271699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>-0.292452</td>\n",
       "      <td>-0.146561</td>\n",
       "      <td>1.067835</td>\n",
       "      <td>0.962348</td>\n",
       "      <td>1.176170</td>\n",
       "      <td>0.197516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>0.049192</td>\n",
       "      <td>-0.156223</td>\n",
       "      <td>0.334081</td>\n",
       "      <td>-0.016991</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.219964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>1.269351</td>\n",
       "      <td>-0.030623</td>\n",
       "      <td>0.242362</td>\n",
       "      <td>0.301294</td>\n",
       "      <td>0.424665</td>\n",
       "      <td>0.197516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>0.878900</td>\n",
       "      <td>-0.175932</td>\n",
       "      <td>0.792677</td>\n",
       "      <td>1.452018</td>\n",
       "      <td>0.605026</td>\n",
       "      <td>1.050518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>0.732481</td>\n",
       "      <td>-0.107915</td>\n",
       "      <td>-0.216235</td>\n",
       "      <td>0.374744</td>\n",
       "      <td>0.214244</td>\n",
       "      <td>0.444438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2781 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5    6    7   \\\n",
       "0     1.074125 -0.127238  0.425800  0.399228  0.214244  0.466885  0.0  1.0   \n",
       "1     1.220544  0.050534 -0.399673 -0.359760 -0.507201  0.444438  1.0  0.0   \n",
       "2     0.390837 -0.096321  0.425800 -0.261826  0.154123 -0.094300  1.0  0.0   \n",
       "3    -0.390065 -0.115644  0.517520 -0.016991  0.875568 -0.341222  0.0  1.0   \n",
       "4    -0.390065  0.038940  0.700958 -1.045298 -2.731657 -2.271699  1.0  0.0   \n",
       "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "2776 -0.292452 -0.146561  1.067835  0.962348  1.176170  0.197516  0.0  1.0   \n",
       "2777  0.049192 -0.156223  0.334081 -0.016991  0.063943  0.219964  1.0  0.0   \n",
       "2778  1.269351 -0.030623  0.242362  0.301294  0.424665  0.197516  1.0  0.0   \n",
       "2779  0.878900 -0.175932  0.792677  1.452018  0.605026  1.050518  1.0  0.0   \n",
       "2780  0.732481 -0.107915 -0.216235  0.374744  0.214244  0.444438  1.0  0.0   \n",
       "\n",
       "       8    9   ...   22   23   24   25   26   27   28   29   30   31  \n",
       "0     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2776  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2777  0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2778  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2779  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2780  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[2781 rows x 32 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "dietary-summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2781 samples, validate on 928 samples\n",
      "Epoch 1/15\n",
      "2781/2781 [==============================] - 0s 135us/step - loss: 0.1647 - MSE: 0.1647 - val_loss: 0.0902 - val_MSE: 0.0902\n",
      "Epoch 2/15\n",
      "2781/2781 [==============================] - 0s 20us/step - loss: 0.0760 - MSE: 0.0760 - val_loss: 0.0687 - val_MSE: 0.0687\n",
      "Epoch 3/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0650 - MSE: 0.0650 - val_loss: 0.0639 - val_MSE: 0.0639\n",
      "Epoch 4/15\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.0603 - MSE: 0.0603 - val_loss: 0.0609 - val_MSE: 0.0609\n",
      "Epoch 5/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0569 - MSE: 0.0569 - val_loss: 0.0583 - val_MSE: 0.0583\n",
      "Epoch 6/15\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.0541 - MSE: 0.0541 - val_loss: 0.0566 - val_MSE: 0.0566\n",
      "Epoch 7/15\n",
      "2781/2781 [==============================] - 0s 17us/step - loss: 0.0519 - MSE: 0.0519 - val_loss: 0.0552 - val_MSE: 0.0552\n",
      "Epoch 8/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0501 - MSE: 0.0501 - val_loss: 0.0536 - val_MSE: 0.0536\n",
      "Epoch 9/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0479 - MSE: 0.0479 - val_loss: 0.0524 - val_MSE: 0.0524\n",
      "Epoch 10/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0459 - MSE: 0.0459 - val_loss: 0.0508 - val_MSE: 0.0508\n",
      "Epoch 11/15\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.0444 - MSE: 0.0444 - val_loss: 0.0499 - val_MSE: 0.0499\n",
      "Epoch 12/15\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.0425 - MSE: 0.0425 - val_loss: 0.0503 - val_MSE: 0.0503\n",
      "Epoch 13/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0418 - MSE: 0.0418 - val_loss: 0.0480 - val_MSE: 0.0480\n",
      "Epoch 14/15\n",
      "2781/2781 [==============================] - 0s 19us/step - loss: 0.0401 - MSE: 0.0401 - val_loss: 0.0477 - val_MSE: 0.0477\n",
      "Epoch 15/15\n",
      "2781/2781 [==============================] - 0s 18us/step - loss: 0.0386 - MSE: 0.0386 - val_loss: 0.0473 - val_MSE: 0.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fc842657f0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "model.compile('adam', mse, metrics=['MSE'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=100, epochs=15,\n",
    "          validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-anatomy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
