{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow v 1.15\n",
    "### Basic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow.compat.v1.version' from 'C:\\\\Users\\\\user\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\compat\\\\v1\\\\version\\\\__init__.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic dataset\n",
    "\n",
    "Datasets EDA are in the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "...            ...    ...               ...      ...   ...      ...  \n",
       "887              0      0            211536  13.0000   NaN        S  \n",
       "888              0      0            112053  30.0000   B42        S  \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890              0      0            111369  30.0000  C148        C  \n",
       "891              0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Titanic.csv', index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Name', 'Ticket', \"Cabin\", 'Embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic dataset columns\n",
    "\n",
    "- Survived (TARGET): Flag, true if passanger survived accident\n",
    "- PClass: 1 for 1st class, 2 for 2nd, 3 for 3rd (cat feature)\n",
    "- Sex (cat feature)\n",
    "- Age\n",
    "- SibSp amount of siblings on the board\n",
    "- Parch amount of parents/children on the board\n",
    "- Fare \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass     Sex   Age  SibSp  Parch     Fare\n",
       "PassengerId                                                       \n",
       "1                   0       3    male  22.0      1      0   7.2500\n",
       "2                   1       1  female  38.0      1      0  71.2833\n",
       "3                   1       3  female  26.0      0      0   7.9250\n",
       "4                   1       1  female  35.0      1      0  53.1000\n",
       "5                   0       3    male  35.0      0      0   8.0500\n",
       "...               ...     ...     ...   ...    ...    ...      ...\n",
       "887                 0       2    male  27.0      0      0  13.0000\n",
       "888                 1       1  female  19.0      0      0  30.0000\n",
       "889                 0       3  female   NaN      1      2  23.4500\n",
       "890                 1       1    male  26.0      0      0  30.0000\n",
       "891                 0       3    male  32.0      0      0   7.7500\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_cols = ['Pclass', 'Sex']\n",
    "num_cols = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "y = data['Survived']\n",
    "X = data.drop('Survived', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=13, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()),\n",
    "    \n",
    "])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers =[\n",
    "    ('num', num_trans, num_cols),\n",
    "    ('cat', cat_trans, cat_cols),\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_val = pd.DataFrame(preprocessor.transform(X_val))\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid regression for classification for 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 13.436591466267904\n",
      "Average loss epoch 1: 11.619273821512857\n",
      "Average loss epoch 2: 9.823769781324598\n",
      "Average loss epoch 3: 8.032816304100884\n",
      "Average loss epoch 4: 6.247832218805949\n",
      "Average loss epoch 5: 4.484060419930352\n",
      "Average loss epoch 6: 2.849020799001058\n",
      "Average loss epoch 7: 1.8193436596128676\n",
      "Average loss epoch 8: 1.4733123646842108\n",
      "Average loss epoch 9: 1.1208579738934834\n",
      "Average loss epoch 10: 1.058667739232381\n",
      "Average loss epoch 11: 1.0157776673634846\n",
      "Average loss epoch 12: 0.9718513819906447\n",
      "Average loss epoch 13: 0.9403973089324104\n",
      "Average loss epoch 14: 0.910688042640686\n",
      "Average loss epoch 15: 0.884124861823188\n",
      "Average loss epoch 16: 0.8631609744495816\n",
      "Average loss epoch 17: 0.8426449166403877\n",
      "Average loss epoch 18: 0.825117376115587\n",
      "Average loss epoch 19: 0.809331390592787\n",
      "Average loss epoch 20: 0.7955059740278456\n",
      "Average loss epoch 21: 0.7834124498897128\n",
      "Average loss epoch 22: 0.7725996110174391\n",
      "Average loss epoch 23: 0.7630651394526163\n",
      "Average loss epoch 24: 0.7546148432625664\n",
      "Average loss epoch 25: 0.7471120688650343\n",
      "Average loss epoch 26: 0.7404345141516792\n",
      "Average loss epoch 27: 0.7344692481888665\n",
      "Average loss epoch 28: 0.7291519774330987\n",
      "Average loss epoch 29: 0.7243839502334595\n",
      "Accuracy 0.53\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 30\n",
    "batch_size = 50\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, X_train.shape[1]], name='data') \n",
    "Y = tf.placeholder(tf.float32, [batch_size, 2], name='label')\n",
    "\n",
    "\n",
    "w = tf.get_variable(name='weights',shape=(X_train.shape[1], num_classes), initializer=tf.random_normal_initializer(), )\n",
    "b = tf.get_variable(name = 'bias', shape=(1, num_classes), initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "logits = tf.matmul(X, w) + b \n",
    "\n",
    "\n",
    "entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "preds = tf.nn.sigmoid(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "        n_batches = X_train.shape[0] // batch_size\n",
    "        for j in range(n_batches-1):\n",
    "            X_batch, y_batch = X_train.iloc[j*batch_size:(j+1)*batch_size], y_train.iloc[j*batch_size:(j+1)*batch_size]\n",
    "            _, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y: y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/(n_batches-1)))\n",
    "\n",
    "\n",
    "    total_correct_preds = 0\n",
    "    n_batches = X_test.shape[0] // batch_size\n",
    "    for j in range(n_batches - 1):\n",
    "        X_batch, Y_batch = X_test.iloc[j*batch_size:(j+1)*batch_size], y_test.iloc[j*batch_size:(j+1)*batch_size]\n",
    "        accuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n",
    "        total_correct_preds += accuracy_batch  \n",
    "    print('Accuracy {0}'.format(total_correct_preds/((n_batches - 1) * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_X_train, T_X_test, T_X_val, T_y_train, T_y_test, T_y_val = X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thyroid Disease dataset\n",
    "\n",
    "EDA and preprocessing are taken from HT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset_57_hypothyroid.csv')\n",
    "data = data.drop(['TBG_measured','TBG'], axis=1)\n",
    "for i in ['TSH','T3','TT4','FTI','T4U']:\n",
    "    data[i] = data[i].apply(lambda x: 0 if x == '?' else x)\n",
    "data['sex'] = data['sex'].apply(lambda x: 'U' if x == '?' else x) \n",
    "data['age'] = data['age'].replace('?', np.median(pd.to_numeric(data.query('sex == \"U\" and age != \"?\"')['age']) ))\n",
    "num_cols = [col for col in data.columns if data[col].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = [col for col in data.columns if data[col].nunique() == 2 and data[col][0] in ['t', 'f']]\n",
    "for col in bool_cols:\n",
    "    data[col] = data[col] == 't'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('hypopituitary', axis=1, inplace=True)\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Class'\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[TARGET] != 'secondary_hypothyroid']\n",
    "X = data.drop(TARGET, axis=1)\n",
    "y = data[TARGET]\n",
    "cat_cols = [col for col in X.columns if X[col].dtype =='object']\n",
    "for col in cat_cols:\n",
    "    try:\n",
    "        X[col] = pd.to_numeric(X[col])\n",
    "    except:\n",
    "        pass\n",
    "cat_cols = [col for col in X.columns if X[col].dtype =='object']\n",
    "num_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "bool_cols = [col for col in X.columns if X[col].dtype == 'bool']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "# X_train[cat_cols] = X_train[cat_cols].apply(lambda x: str(x))\n",
    "# X_test[cat_cols] = X_test[cat_cols].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>referral_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>F</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>M</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3709 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex referral_source\n",
       "0      F            SVHC\n",
       "1      F           other\n",
       "2      M           other\n",
       "3      F           other\n",
       "4      F             SVI\n",
       "...   ..             ...\n",
       "3767   F           other\n",
       "3768   F             SVI\n",
       "3769   F           other\n",
       "3770   M             SVI\n",
       "3771   F           other\n",
       "\n",
       "[3709 rows x 2 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val =train_test_split(X_train, y_train, stratify=y_train, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',  StandardScaler())\n",
    "    \n",
    "])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "bool_trans = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers =[\n",
    "    ('num', num_trans, num_cols),\n",
    "    ('cat', cat_trans, cat_cols),\n",
    "    ('bool', bool_trans, bool_cols)\n",
    "], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_val = pd.DataFrame(preprocessor.transform(X_val))\n",
    "X_test = pd.DataFrame(preprocessor.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.238671</td>\n",
       "      <td>-0.078589</td>\n",
       "      <td>0.524788</td>\n",
       "      <td>0.642052</td>\n",
       "      <td>0.172122</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.759919</td>\n",
       "      <td>-0.141410</td>\n",
       "      <td>-1.562062</td>\n",
       "      <td>-0.229984</td>\n",
       "      <td>0.321821</td>\n",
       "      <td>-0.177715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472667</td>\n",
       "      <td>-0.137715</td>\n",
       "      <td>0.809358</td>\n",
       "      <td>-0.332577</td>\n",
       "      <td>0.321821</td>\n",
       "      <td>-0.247083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424792</td>\n",
       "      <td>-0.149170</td>\n",
       "      <td>-0.139210</td>\n",
       "      <td>-1.050724</td>\n",
       "      <td>-1.055404</td>\n",
       "      <td>0.284738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.293336</td>\n",
       "      <td>-0.134019</td>\n",
       "      <td>-0.328923</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.441579</td>\n",
       "      <td>-0.038979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>1.047170</td>\n",
       "      <td>-0.126629</td>\n",
       "      <td>-0.898064</td>\n",
       "      <td>-0.563410</td>\n",
       "      <td>-0.097335</td>\n",
       "      <td>-0.177715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>0.903544</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.145361</td>\n",
       "      <td>-0.435169</td>\n",
       "      <td>-0.067395</td>\n",
       "      <td>-0.062102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>1.142920</td>\n",
       "      <td>0.043359</td>\n",
       "      <td>-1.087778</td>\n",
       "      <td>0.667700</td>\n",
       "      <td>-0.187154</td>\n",
       "      <td>1.209644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.999295</td>\n",
       "      <td>-0.185755</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>-2.666556</td>\n",
       "      <td>-2.732026</td>\n",
       "      <td>-2.328122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>0.520543</td>\n",
       "      <td>-0.145105</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>-0.358225</td>\n",
       "      <td>-0.097335</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5    6    7   \\\n",
       "0     1.238671 -0.078589  0.524788  0.642052  0.172122  0.747191  1.0  0.0   \n",
       "1     0.759919 -0.141410 -1.562062 -0.229984  0.321821 -0.177715  1.0  0.0   \n",
       "2     0.472667 -0.137715  0.809358 -0.332577  0.321821 -0.247083  0.0  1.0   \n",
       "3     0.424792 -0.149170 -0.139210 -1.050724 -1.055404  0.284738  1.0  0.0   \n",
       "4    -0.293336 -0.134019 -0.328923  0.000849  0.441579 -0.038979  1.0  0.0   \n",
       "...        ...       ...       ...       ...       ...       ...  ...  ...   \n",
       "2080  1.047170 -0.126629 -0.898064 -0.563410 -0.097335 -0.177715  1.0  0.0   \n",
       "2081  0.903544  0.002710  0.145361 -0.435169 -0.067395 -0.062102  1.0  0.0   \n",
       "2082  1.142920  0.043359 -1.087778  0.667700 -0.187154  1.209644  1.0  0.0   \n",
       "2083  0.999295 -0.185755  0.429931 -2.666556 -2.732026 -2.328122  1.0  0.0   \n",
       "2084  0.520543 -0.145105  0.619645 -0.358225 -0.097335  0.030389  0.0  1.0   \n",
       "\n",
       "       8    9   ...   22   23   24   25   26   27   28   29   30   31  \n",
       "0     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  1.0  \n",
       "2     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "2080  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2081  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2082  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2083  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "2084  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[2085 rows x 32 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y_train = pd.DataFrame()\n",
    "_y_test = pd.DataFrame()\n",
    "_y_val = pd.DataFrame()\n",
    "for j in range(pd.Series(y_train).nunique()):\n",
    "    _y_train[j] = y_train == j\n",
    "    _y_test[j] = y_test == j\n",
    "    _y_val[j] = y_val == j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2\n",
       "0    False   True  False\n",
       "1    False   True  False\n",
       "2     True  False  False\n",
       "3    False   True  False\n",
       "4    False   True  False\n",
       "..     ...    ...    ...\n",
       "923   True  False  False\n",
       "924  False   True  False\n",
       "925   True  False  False\n",
       "926  False   True  False\n",
       "927  False   True  False\n",
       "\n",
       "[928 rows x 3 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss epoch 0: 0.8118330804925216\n",
      "Average loss epoch 1: 0.6678380777961329\n",
      "Average loss epoch 2: 0.574460694664403\n",
      "Average loss epoch 3: 0.49968413302772924\n",
      "Average loss epoch 4: 0.4377234782043256\n",
      "Average loss epoch 5: 0.38402592900552246\n",
      "Average loss epoch 6: 0.3368039389974193\n",
      "Average loss epoch 7: 0.2961645479265012\n",
      "Average loss epoch 8: 0.26354410303266423\n",
      "Average loss epoch 9: 0.24153421505501396\n",
      "Average loss epoch 10: 0.22962592542171478\n",
      "Average loss epoch 11: 0.2219455649978236\n",
      "Average loss epoch 12: 0.21604218098678088\n",
      "Average loss epoch 13: 0.2111607711566122\n",
      "Average loss epoch 14: 0.20697614942726336\n",
      "Average loss epoch 15: 0.2032988381228949\n",
      "Average loss epoch 16: 0.20000599520771126\n",
      "Average loss epoch 17: 0.19701619171782545\n",
      "Average loss epoch 18: 0.1942725110995142\n",
      "Average loss epoch 19: 0.1917337555634348\n",
      "Average loss epoch 20: 0.18936909107785477\n",
      "Average loss epoch 21: 0.18715486949995944\n",
      "Average loss epoch 22: 0.1850724467321446\n",
      "Average loss epoch 23: 0.18310680867809997\n",
      "Average loss epoch 24: 0.1812456234505302\n",
      "Average loss epoch 25: 0.1794785751323951\n",
      "Average loss epoch 26: 0.1777969006645052\n",
      "Average loss epoch 27: 0.17619306907842033\n",
      "Average loss epoch 28: 0.17466054033291967\n",
      "Average loss epoch 29: 0.17319355199211522\n",
      "Accuracy 0.94625\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = _y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "n_epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, X_train.shape[1]], name='data') \n",
    "Y = tf.placeholder(tf.int32, [batch_size, num_classes], name='label')\n",
    "\n",
    "\n",
    "w = tf.get_variable(name='weights',shape=(X_train.shape[1], num_classes), initializer=tf.random_normal_initializer(), )\n",
    "b = tf.get_variable(name = 'bias', shape=(1, num_classes), initializer=tf.zeros_initializer())\n",
    "\n",
    "\n",
    "logits = tf.matmul(X, w) + b \n",
    "\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    \n",
    "\n",
    "    for i in range(n_epochs): \n",
    "        total_loss = 0\n",
    "        n_batches = X_train.shape[0] // batch_size\n",
    "        for j in range(n_batches-1):\n",
    "            X_batch, y_batch = X_train.iloc[j*batch_size:(j+1)*batch_size], _y_train.iloc[j*batch_size:(j+1)*batch_size]\n",
    "            _, loss_batch = sess.run([optimizer, loss], {X: X_batch, Y: y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print('Average loss epoch {0}: {1}'.format(i, total_loss/(n_batches-1)))\n",
    "\n",
    "\n",
    "    total_correct_preds = 0\n",
    "    n_batches = X_test.shape[0] // batch_size\n",
    "    for j in range(n_batches - 1):\n",
    "        X_batch, Y_batch = X_test.iloc[j*batch_size:(j+1)*batch_size], _y_test.iloc[j*batch_size:(j+1)*batch_size]\n",
    "        accuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n",
    "        total_correct_preds += accuracy_batch  \n",
    "    print('Accuracy {0}'.format(total_correct_preds/((n_batches - 1) * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_X_train, TD_y_train, TD_X_test, TD_y_test, TD_X_val, TD_y_val = X_train, _y_train, X_test, _y_test, X_val, _y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.3208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2        3    4    5    6    7    8\n",
       "0    29.0  1.0  0.0   7.0458  0.0  0.0  1.0  0.0  1.0\n",
       "1    28.0  0.0  0.0   9.5000  0.0  0.0  1.0  0.0  1.0\n",
       "2    31.0  1.0  0.0  57.0000  1.0  0.0  0.0  0.0  1.0\n",
       "3    35.8  0.0  0.0  15.0500  0.0  1.0  0.0  0.0  1.0\n",
       "4    36.5  0.0  2.0  26.0000  0.0  1.0  0.0  0.0  1.0\n",
       "..    ...  ...  ...      ...  ...  ...  ...  ...  ...\n",
       "496   3.0  4.0  2.0  31.3875  0.0  0.0  1.0  0.0  1.0\n",
       "497  61.0  0.0  0.0  32.3208  1.0  0.0  0.0  0.0  1.0\n",
       "498  31.0  0.0  0.0   7.8542  0.0  0.0  1.0  1.0  0.0\n",
       "499   4.0  4.0  1.0  29.1250  0.0  0.0  1.0  0.0  1.0\n",
       "500  38.0  0.0  0.0  80.0000  1.0  0.0  0.0  1.0  0.0\n",
       "\n",
       "[501 rows x 9 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 501 samples, validate on 167 samples\n",
      "Epoch 1/30\n",
      "501/501 [==============================] - 0s 704us/sample - loss: 4.5854 - accuracy: 0.3014 - auc_4: 0.3189 - val_loss: 3.9049 - val_accuracy: 0.3054 - val_auc_4: 0.3111\n",
      "Epoch 2/30\n",
      "501/501 [==============================] - 0s 47us/sample - loss: 4.3753 - accuracy: 0.2994 - auc_4: 0.3205 - val_loss: 3.7300 - val_accuracy: 0.3114 - val_auc_4: 0.3142\n",
      "Epoch 3/30\n",
      "501/501 [==============================] - 0s 50us/sample - loss: 4.1820 - accuracy: 0.2974 - auc_4: 0.3211 - val_loss: 3.5502 - val_accuracy: 0.3114 - val_auc_4: 0.3156\n",
      "Epoch 4/30\n",
      "501/501 [==============================] - 0s 50us/sample - loss: 3.9706 - accuracy: 0.2974 - auc_4: 0.3208 - val_loss: 3.3766 - val_accuracy: 0.3114 - val_auc_4: 0.3182\n",
      "Epoch 5/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 3.7786 - accuracy: 0.2994 - auc_4: 0.3235 - val_loss: 3.2071 - val_accuracy: 0.3114 - val_auc_4: 0.3204\n",
      "Epoch 6/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 3.5840 - accuracy: 0.2974 - auc_4: 0.3279 - val_loss: 3.0405 - val_accuracy: 0.3054 - val_auc_4: 0.3236\n",
      "Epoch 7/30\n",
      "501/501 [==============================] - 0s 43us/sample - loss: 3.3921 - accuracy: 0.2974 - auc_4: 0.3319 - val_loss: 2.8728 - val_accuracy: 0.2994 - val_auc_4: 0.3275\n",
      "Epoch 8/30\n",
      "501/501 [==============================] - 0s 47us/sample - loss: 3.2069 - accuracy: 0.2994 - auc_4: 0.3319 - val_loss: 2.7168 - val_accuracy: 0.2994 - val_auc_4: 0.3302\n",
      "Epoch 9/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 3.0224 - accuracy: 0.3014 - auc_4: 0.3355 - val_loss: 2.5608 - val_accuracy: 0.2994 - val_auc_4: 0.3313\n",
      "Epoch 10/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 2.8522 - accuracy: 0.3014 - auc_4: 0.3386 - val_loss: 2.4086 - val_accuracy: 0.2994 - val_auc_4: 0.3353\n",
      "Epoch 11/30\n",
      "501/501 [==============================] - 0s 45us/sample - loss: 2.6825 - accuracy: 0.3034 - auc_4: 0.3431 - val_loss: 2.2656 - val_accuracy: 0.2994 - val_auc_4: 0.3389\n",
      "Epoch 12/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 2.5004 - accuracy: 0.3074 - auc_4: 0.3484 - val_loss: 2.1114 - val_accuracy: 0.3114 - val_auc_4: 0.3462\n",
      "Epoch 13/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 2.3333 - accuracy: 0.3134 - auc_4: 0.3541 - val_loss: 1.9781 - val_accuracy: 0.3114 - val_auc_4: 0.3496\n",
      "Epoch 14/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 2.1830 - accuracy: 0.3194 - auc_4: 0.3596 - val_loss: 1.8519 - val_accuracy: 0.3114 - val_auc_4: 0.3544\n",
      "Epoch 15/30\n",
      "501/501 [==============================] - 0s 49us/sample - loss: 2.0404 - accuracy: 0.3194 - auc_4: 0.3665 - val_loss: 1.7352 - val_accuracy: 0.3174 - val_auc_4: 0.3578\n",
      "Epoch 16/30\n",
      "501/501 [==============================] - 0s 38us/sample - loss: 1.9022 - accuracy: 0.3373 - auc_4: 0.3755 - val_loss: 1.6164 - val_accuracy: 0.3174 - val_auc_4: 0.3635\n",
      "Epoch 17/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 1.7656 - accuracy: 0.3453 - auc_4: 0.3830 - val_loss: 1.5011 - val_accuracy: 0.3293 - val_auc_4: 0.3745\n",
      "Epoch 18/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 1.6289 - accuracy: 0.3713 - auc_4: 0.3950 - val_loss: 1.3865 - val_accuracy: 0.3353 - val_auc_4: 0.3888\n",
      "Epoch 19/30\n",
      "501/501 [==============================] - 0s 50us/sample - loss: 1.4930 - accuracy: 0.3812 - auc_4: 0.4078 - val_loss: 1.2830 - val_accuracy: 0.3413 - val_auc_4: 0.4011\n",
      "Epoch 20/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 1.3679 - accuracy: 0.3653 - auc_4: 0.4229 - val_loss: 1.1778 - val_accuracy: 0.3473 - val_auc_4: 0.4172\n",
      "Epoch 21/30\n",
      "501/501 [==============================] - 0s 45us/sample - loss: 1.2398 - accuracy: 0.3573 - auc_4: 0.4395 - val_loss: 1.0878 - val_accuracy: 0.3473 - val_auc_4: 0.4320\n",
      "Epoch 22/30\n",
      "501/501 [==============================] - 0s 47us/sample - loss: 1.1290 - accuracy: 0.3673 - auc_4: 0.4568 - val_loss: 1.0035 - val_accuracy: 0.3533 - val_auc_4: 0.4490\n",
      "Epoch 23/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 1.0186 - accuracy: 0.3673 - auc_4: 0.4754 - val_loss: 0.9186 - val_accuracy: 0.3772 - val_auc_4: 0.4783\n",
      "Epoch 24/30\n",
      "501/501 [==============================] - 0s 38us/sample - loss: 0.9167 - accuracy: 0.3892 - auc_4: 0.5019 - val_loss: 0.8364 - val_accuracy: 0.3952 - val_auc_4: 0.5117\n",
      "Epoch 25/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 0.8283 - accuracy: 0.4391 - auc_4: 0.5282 - val_loss: 0.7669 - val_accuracy: 0.4551 - val_auc_4: 0.5413\n",
      "Epoch 26/30\n",
      "501/501 [==============================] - 0s 36us/sample - loss: 0.7509 - accuracy: 0.5369 - auc_4: 0.5637 - val_loss: 0.7156 - val_accuracy: 0.5389 - val_auc_4: 0.5894\n",
      "Epoch 27/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.6892 - accuracy: 0.6307 - auc_4: 0.6349 - val_loss: 0.6713 - val_accuracy: 0.7006 - val_auc_4: 0.6728\n",
      "Epoch 28/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 0.6398 - accuracy: 0.7565 - auc_4: 0.7093 - val_loss: 0.6375 - val_accuracy: 0.7605 - val_auc_4: 0.7228\n",
      "Epoch 29/30\n",
      "501/501 [==============================] - 0s 48us/sample - loss: 0.6052 - accuracy: 0.7844 - auc_4: 0.7393 - val_loss: 0.6119 - val_accuracy: 0.7725 - val_auc_4: 0.7668\n",
      "Epoch 30/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.5817 - accuracy: 0.7904 - auc_4: 0.7676 - val_loss: 0.5954 - val_accuracy: 0.7725 - val_auc_4: 0.7828\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(titanic_X_train.shape[1],)))\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(T_X_train, T_y_train,\n",
    "          batch_size=50, epochs=30,\n",
    "          validation_data = (T_X_val, T_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(T_y_val ,model.predict(T_X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc_curve(fpr,tpr): \n",
    "    plt.plot(fpr,tpr) \n",
    "    plt.axis([0,1,0,1]) \n",
    "    plt.xlabel('False Positive Rate') \n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr,tpr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 501 samples, validate on 167 samples\n",
      "Epoch 1/30\n",
      " 50/501 [=>............................] - ETA: 0s - loss: 0.9245 - accuracy: 0.6600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501/501 [==============================] - 0s 623us/sample - loss: 2.5337 - accuracy: 0.6188 - val_loss: 1.9095 - val_accuracy: 0.5928\n",
      "Epoch 2/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 2.4042 - accuracy: 0.6148 - val_loss: 1.8248 - val_accuracy: 0.5928\n",
      "Epoch 3/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 2.2951 - accuracy: 0.6148 - val_loss: 1.7185 - val_accuracy: 0.6108\n",
      "Epoch 4/30\n",
      "501/501 [==============================] - 0s 39us/sample - loss: 2.1679 - accuracy: 0.6168 - val_loss: 1.6173 - val_accuracy: 0.6168\n",
      "Epoch 5/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 2.0397 - accuracy: 0.6208 - val_loss: 1.5196 - val_accuracy: 0.6168\n",
      "Epoch 6/30\n",
      "501/501 [==============================] - 0s 36us/sample - loss: 1.9147 - accuracy: 0.6267 - val_loss: 1.4252 - val_accuracy: 0.6048\n",
      "Epoch 7/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 1.7926 - accuracy: 0.6208 - val_loss: 1.3410 - val_accuracy: 0.6287\n",
      "Epoch 8/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 1.6942 - accuracy: 0.6248 - val_loss: 1.2553 - val_accuracy: 0.6287\n",
      "Epoch 9/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 1.5701 - accuracy: 0.6267 - val_loss: 1.1639 - val_accuracy: 0.6407\n",
      "Epoch 10/30\n",
      "501/501 [==============================] - 0s 52us/sample - loss: 1.4631 - accuracy: 0.6427 - val_loss: 1.0941 - val_accuracy: 0.6287\n",
      "Epoch 11/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 1.3715 - accuracy: 0.6607 - val_loss: 1.0398 - val_accuracy: 0.6228\n",
      "Epoch 12/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 1.2963 - accuracy: 0.6607 - val_loss: 0.9835 - val_accuracy: 0.6228\n",
      "Epoch 13/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 1.2269 - accuracy: 0.6627 - val_loss: 0.9342 - val_accuracy: 0.6228\n",
      "Epoch 14/30\n",
      "501/501 [==============================] - 0s 41us/sample - loss: 1.1618 - accuracy: 0.6667 - val_loss: 0.8914 - val_accuracy: 0.6347\n",
      "Epoch 15/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 1.1107 - accuracy: 0.6687 - val_loss: 0.8552 - val_accuracy: 0.6407\n",
      "Epoch 16/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 1.0623 - accuracy: 0.6806 - val_loss: 0.8251 - val_accuracy: 0.6407\n",
      "Epoch 17/30\n",
      "501/501 [==============================] - 0s 41us/sample - loss: 1.0210 - accuracy: 0.6826 - val_loss: 0.7945 - val_accuracy: 0.6467\n",
      "Epoch 18/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.9734 - accuracy: 0.6846 - val_loss: 0.7636 - val_accuracy: 0.6527\n",
      "Epoch 19/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 0.9314 - accuracy: 0.6866 - val_loss: 0.7361 - val_accuracy: 0.6347\n",
      "Epoch 20/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 0.8940 - accuracy: 0.6826 - val_loss: 0.7133 - val_accuracy: 0.6527\n",
      "Epoch 21/30\n",
      "501/501 [==============================] - 0s 41us/sample - loss: 0.8631 - accuracy: 0.6926 - val_loss: 0.6985 - val_accuracy: 0.6527\n",
      "Epoch 22/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.8431 - accuracy: 0.6946 - val_loss: 0.6824 - val_accuracy: 0.6587\n",
      "Epoch 23/30\n",
      "501/501 [==============================] - 0s 46us/sample - loss: 0.8207 - accuracy: 0.6906 - val_loss: 0.6654 - val_accuracy: 0.6707\n",
      "Epoch 24/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.7858 - accuracy: 0.6966 - val_loss: 0.6509 - val_accuracy: 0.6826\n",
      "Epoch 25/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 0.7566 - accuracy: 0.6906 - val_loss: 0.6435 - val_accuracy: 0.7006\n",
      "Epoch 26/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 0.7167 - accuracy: 0.6926 - val_loss: 0.6366 - val_accuracy: 0.7066\n",
      "Epoch 27/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.6993 - accuracy: 0.7066 - val_loss: 0.6285 - val_accuracy: 0.7126\n",
      "Epoch 28/30\n",
      "501/501 [==============================] - 0s 40us/sample - loss: 0.6880 - accuracy: 0.7106 - val_loss: 0.6222 - val_accuracy: 0.7126\n",
      "Epoch 29/30\n",
      "501/501 [==============================] - 0s 44us/sample - loss: 0.6799 - accuracy: 0.7126 - val_loss: 0.6177 - val_accuracy: 0.7246\n",
      "Epoch 30/30\n",
      "501/501 [==============================] - 0s 42us/sample - loss: 0.6708 - accuracy: 0.7146 - val_loss: 0.6201 - val_accuracy: 0.7186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x191116d6d48>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_shape=(T_X_train.shape[1],)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(T_X_train, T_y_train,\n",
    "          batch_size=50, epochs=30,\n",
    "          validation_data = (T_X_val, T_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Log_los is  0.7308172887935608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print('Test Log_los is ', log_loss(T_y_test, model.predict(T_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(T_y_test ,model.predict(T_X_test))\n",
    "plot_roc_curve(fpr,tpr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thyroid Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2085 samples, validate on 696 samples\n",
      "Epoch 1/20\n",
      " 100/2085 [>.............................] - ETA: 1s - loss: 1.8990 - accuracy: 0.1500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085/2085 [==============================] - 0s 150us/sample - loss: 1.7836 - accuracy: 0.1329 - val_loss: 1.6531 - val_accuracy: 0.1609\n",
      "Epoch 2/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 1.5329 - accuracy: 0.1914 - val_loss: 1.4139 - val_accuracy: 0.2443\n",
      "Epoch 3/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 1.3079 - accuracy: 0.2830 - val_loss: 1.2037 - val_accuracy: 0.3534\n",
      "Epoch 4/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 1.1128 - accuracy: 0.4158 - val_loss: 1.0238 - val_accuracy: 0.4756\n",
      "Epoch 5/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.9476 - accuracy: 0.5683 - val_loss: 0.8739 - val_accuracy: 0.6293\n",
      "Epoch 6/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.8116 - accuracy: 0.6882 - val_loss: 0.7514 - val_accuracy: 0.7170\n",
      "Epoch 7/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.7020 - accuracy: 0.7679 - val_loss: 0.6528 - val_accuracy: 0.7902\n",
      "Epoch 8/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.6139 - accuracy: 0.8504 - val_loss: 0.5763 - val_accuracy: 0.8721\n",
      "Epoch 9/20\n",
      "2085/2085 [==============================] - 0s 18us/sample - loss: 0.5459 - accuracy: 0.9046 - val_loss: 0.5150 - val_accuracy: 0.9181\n",
      "Epoch 10/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.4918 - accuracy: 0.9285 - val_loss: 0.4671 - val_accuracy: 0.9282\n",
      "Epoch 11/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.4494 - accuracy: 0.9338 - val_loss: 0.4295 - val_accuracy: 0.9282\n",
      "Epoch 12/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.4159 - accuracy: 0.9357 - val_loss: 0.3998 - val_accuracy: 0.9296\n",
      "Epoch 13/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.3895 - accuracy: 0.9348 - val_loss: 0.3759 - val_accuracy: 0.9282\n",
      "Epoch 14/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.3683 - accuracy: 0.9348 - val_loss: 0.3565 - val_accuracy: 0.9310\n",
      "Epoch 15/20\n",
      "2085/2085 [==============================] - 0s 15us/sample - loss: 0.3509 - accuracy: 0.9348 - val_loss: 0.3409 - val_accuracy: 0.9310\n",
      "Epoch 16/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.3368 - accuracy: 0.9353 - val_loss: 0.3279 - val_accuracy: 0.9282\n",
      "Epoch 17/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.3250 - accuracy: 0.9348 - val_loss: 0.3171 - val_accuracy: 0.9282\n",
      "Epoch 18/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.3151 - accuracy: 0.9338 - val_loss: 0.3081 - val_accuracy: 0.9282\n",
      "Epoch 19/20\n",
      "2085/2085 [==============================] - 0s 16us/sample - loss: 0.3068 - accuracy: 0.9333 - val_loss: 0.3003 - val_accuracy: 0.9282\n",
      "Epoch 20/20\n",
      "2085/2085 [==============================] - 0s 17us/sample - loss: 0.2996 - accuracy: 0.9333 - val_loss: 0.2936 - val_accuracy: 0.9282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x191117bca48>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(TD_y_train.shape[1], activation='softmax', input_shape=(TD_X_train.shape[1],)))\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(TD_X_train, TD_y_train,\n",
    "          batch_size=100, epochs=20,\n",
    "          validation_data = (TD_X_val, TD_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Log_los is  0.30546817836022516\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print('Test Log_los is ', log_loss(TD_y_test, model.predict(TD_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    fpr, tpr, thresholds = roc_curve(TD_y_test[i], model.predict(TD_X_test)[:,i])\n",
    "    plot_roc_curve(fpr,tpr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "boston_data = pd.DataFrame(boston.data, columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_target = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in boston_data.columns\n",
    "                     if boston_data[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston_data, boston_target, random_state=SEED)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.14103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>5.790</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.3200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>15.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.13554</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>5.594</td>\n",
       "      <td>36.8</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.21038</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>6.812</td>\n",
       "      <td>32.2</td>\n",
       "      <td>4.1007</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.08199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>6.009</td>\n",
       "      <td>42.3</td>\n",
       "      <td>5.5027</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5730</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.10008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>6.563</td>\n",
       "      <td>95.6</td>\n",
       "      <td>2.8470</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.61282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.096</td>\n",
       "      <td>96.9</td>\n",
       "      <td>3.7598</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>248.31</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.04560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>5.888</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.1121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>392.80</td>\n",
       "      <td>13.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.03502</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>6.861</td>\n",
       "      <td>27.9</td>\n",
       "      <td>5.1167</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "297  0.14103   0.0  13.92   0.0  0.4370  5.790  58.0  6.3200   4.0  289.0   \n",
       "487  4.83567   0.0  18.10   0.0  0.5830  5.905  53.2  3.1523  24.0  666.0   \n",
       "68   0.13554  12.5   6.07   0.0  0.4090  5.594  36.8  6.4980   4.0  345.0   \n",
       "279  0.21038  20.0   3.33   0.0  0.4429  6.812  32.2  4.1007   5.0  216.0   \n",
       "294  0.08199   0.0  13.92   0.0  0.4370  6.009  42.3  5.5027   4.0  289.0   \n",
       "..       ...   ...    ...   ...     ...    ...   ...     ...   ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.5730  6.593  69.1  2.4786   1.0  273.0   \n",
       "183  0.10008   0.0   2.46   0.0  0.4880  6.563  95.6  2.8470   3.0  193.0   \n",
       "34   1.61282   0.0   8.14   0.0  0.5380  6.096  96.9  3.7598   4.0  307.0   \n",
       "216  0.04560   0.0  13.89   1.0  0.5500  5.888  56.0  3.1121   5.0  276.0   \n",
       "290  0.03502  80.0   4.95   0.0  0.4110  6.861  27.9  5.1167   4.0  245.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "297     16.0  396.90  15.84  \n",
       "487     20.2  388.22  11.45  \n",
       "68      18.9  396.90  13.09  \n",
       "279     14.9  396.90   4.85  \n",
       "294     16.0  396.90  10.40  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "183     17.8  396.90   5.68  \n",
       "34      21.0  248.31  20.34  \n",
       "216     16.4  392.80  13.51  \n",
       "290     19.2  396.90   3.33  \n",
       "\n",
       "[284 rows x 13 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/15\n",
      "284/284 [==============================] - 0s 734us/sample - loss: 212.6795 - MSE: 212.6796 - MAE: 12.2239 - val_loss: 120.3602 - val_MSE: 120.3602 - val_MAE: 9.6101\n",
      "Epoch 2/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 98.1367 - MSE: 98.1367 - MAE: 7.8235 - val_loss: 105.4185 - val_MSE: 105.4185 - val_MAE: 7.6889\n",
      "Epoch 3/15\n",
      "284/284 [==============================] - 0s 39us/sample - loss: 121.3784 - MSE: 121.3784 - MAE: 7.8824 - val_loss: 64.7804 - val_MSE: 64.7804 - val_MAE: 6.4849\n",
      "Epoch 4/15\n",
      "284/284 [==============================] - 0s 35us/sample - loss: 90.9554 - MSE: 90.9554 - MAE: 7.6641 - val_loss: 99.8528 - val_MSE: 99.8528 - val_MAE: 8.7081\n",
      "Epoch 5/15\n",
      "100/284 [=========>....................] - ETA: 0s - loss: 99.2165 - MSE: 99.2165 - MAE: 8.6132"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 0s 35us/sample - loss: 89.4778 - MSE: 89.4778 - MAE: 7.7240 - val_loss: 51.4141 - val_MSE: 51.4141 - val_MAE: 5.3982\n",
      "Epoch 6/15\n",
      "284/284 [==============================] - 0s 35us/sample - loss: 74.2231 - MSE: 74.2231 - MAE: 5.7167 - val_loss: 59.3019 - val_MSE: 59.3019 - val_MAE: 5.6519\n",
      "Epoch 7/15\n",
      "284/284 [==============================] - 0s 31us/sample - loss: 72.3112 - MSE: 72.3112 - MAE: 5.6890 - val_loss: 57.2351 - val_MSE: 57.2351 - val_MAE: 5.9551\n",
      "Epoch 8/15\n",
      "284/284 [==============================] - 0s 35us/sample - loss: 67.6244 - MSE: 67.6244 - MAE: 6.2934 - val_loss: 53.2475 - val_MSE: 53.2475 - val_MAE: 5.9081\n",
      "Epoch 9/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 62.9674 - MSE: 62.9674 - MAE: 5.7069 - val_loss: 50.9517 - val_MSE: 50.9517 - val_MAE: 5.4028\n",
      "Epoch 10/15\n",
      "284/284 [==============================] - 0s 35us/sample - loss: 61.7417 - MSE: 61.7417 - MAE: 5.5257 - val_loss: 49.6995 - val_MSE: 49.6995 - val_MAE: 5.4437\n",
      "Epoch 11/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 57.4498 - MSE: 57.4498 - MAE: 5.4971 - val_loss: 49.4141 - val_MSE: 49.4141 - val_MAE: 5.2299\n",
      "Epoch 12/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 59.2577 - MSE: 59.2577 - MAE: 5.1448 - val_loss: 46.2466 - val_MSE: 46.2466 - val_MAE: 5.0843\n",
      "Epoch 13/15\n",
      "284/284 [==============================] - 0s 31us/sample - loss: 53.5636 - MSE: 53.5636 - MAE: 5.1624 - val_loss: 51.3923 - val_MSE: 51.3923 - val_MAE: 5.7865\n",
      "Epoch 14/15\n",
      "284/284 [==============================] - 0s 30us/sample - loss: 54.7670 - MSE: 54.7670 - MAE: 5.6113 - val_loss: 45.8529 - val_MSE: 45.8529 - val_MAE: 5.2659\n",
      "Epoch 15/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 54.5598 - MSE: 54.5598 - MAE: 5.0689 - val_loss: 44.2705 - val_MSE: 44.2705 - val_MAE: 4.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1910b07adc8>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "  ])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "model.compile('adam', mse, metrics=['MSE', 'MAE'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=100, epochs=15,\n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score at test sample  0.31891632171198603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2 score at test sample ', r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/15\n",
      "284/284 [==============================] - 0s 849us/sample - loss: 4265.2530 - MSE: 4265.2529 - MAE: 39.0029 - val_loss: 2975.0769 - val_MSE: 2975.0769 - val_MAE: 33.9645\n",
      "Epoch 2/15\n",
      "284/284 [==============================] - 0s 33us/sample - loss: 4145.5815 - MSE: 4145.5820 - MAE: 38.1258 - val_loss: 2886.0537 - val_MSE: 2886.0537 - val_MAE: 33.2031\n",
      "Epoch 3/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 4039.9893 - MSE: 4039.9895 - MAE: 37.3663 - val_loss: 2802.6516 - val_MSE: 2802.6516 - val_MAE: 32.5308\n",
      "Epoch 4/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3942.6533 - MSE: 3942.6531 - MAE: 36.6681 - val_loss: 2725.6040 - val_MSE: 2725.6040 - val_MAE: 31.8988\n",
      "Epoch 5/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3846.6579 - MSE: 3846.6580 - MAE: 36.1684 - val_loss: 2655.5173 - val_MSE: 2655.5173 - val_MAE: 31.4259\n",
      "Epoch 6/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 3752.7456 - MSE: 3752.7456 - MAE: 35.7739 - val_loss: 2592.6658 - val_MSE: 2592.6658 - val_MAE: 31.0453\n",
      "Epoch 7/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 3681.6287 - MSE: 3681.6287 - MAE: 35.5351 - val_loss: 2534.7134 - val_MSE: 2534.7134 - val_MAE: 30.7157\n",
      "Epoch 8/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3604.9920 - MSE: 3604.9922 - MAE: 35.3452 - val_loss: 2483.8564 - val_MSE: 2483.8564 - val_MAE: 30.5843\n",
      "Epoch 9/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3543.1162 - MSE: 3543.1162 - MAE: 35.3867 - val_loss: 2437.6592 - val_MSE: 2437.6592 - val_MAE: 30.6738\n",
      "Epoch 10/15\n",
      "284/284 [==============================] - 0s 32us/sample - loss: 3476.3033 - MSE: 3476.3032 - MAE: 35.4716 - val_loss: 2394.5276 - val_MSE: 2394.5276 - val_MAE: 30.7659\n",
      "Epoch 11/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3420.6641 - MSE: 3420.6641 - MAE: 35.5921 - val_loss: 2352.3713 - val_MSE: 2352.3713 - val_MAE: 30.7838\n",
      "Epoch 12/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3360.5676 - MSE: 3360.5674 - MAE: 35.5367 - val_loss: 2311.4917 - val_MSE: 2311.4917 - val_MAE: 30.7274\n",
      "Epoch 13/15\n",
      "284/284 [==============================] - 0s 31us/sample - loss: 3302.9221 - MSE: 3302.9221 - MAE: 35.4135 - val_loss: 2271.0386 - val_MSE: 2271.0386 - val_MAE: 30.6265\n",
      "Epoch 14/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3244.0259 - MSE: 3244.0256 - MAE: 35.2719 - val_loss: 2230.4409 - val_MSE: 2230.4409 - val_MAE: 30.4651\n",
      "Epoch 15/15\n",
      "284/284 [==============================] - 0s 28us/sample - loss: 3193.1280 - MSE: 3193.1282 - MAE: 35.1275 - val_loss: 2189.0737 - val_MSE: 2189.0737 - val_MAE: 30.3579\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation='relu', input_shape=[X_train.shape[1]])\n",
    "  ])\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "model.compile('adam', mse, metrics=['MSE', 'MAE'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=100, epochs=15,\n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1910e0d2a88>]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score at test sample  -5.348119604777846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print('R2 score at test sample ', r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многослойные нейронные сети выигрывают в точности у однослойных за счет большего количества настраиваемых параметров и \"встроенного\" создания доп. признаков из комбинирования старых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
