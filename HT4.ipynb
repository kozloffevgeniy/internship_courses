{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже использует лемматизатор, для получения формы слова, убирает лишние символы и слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-68b196a0e6a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/neg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/neg/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtext_prep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'neg'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "train_path = 'aclImdb/train'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def text_prep(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    lemma_words = ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "    return lemma_words\n",
    "\n",
    "    \n",
    "train = pd.DataFrame(columns=['review', 'class'])\n",
    "for file in os.listdir(train_path + '/neg'):\n",
    "    f = open(train_path + '/neg/' + file, 'r',  encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    train = train.append({'review':text_prep(text), 'class':'neg'}, ignore_index=True)\n",
    "    \n",
    "\n",
    "for file in os.listdir(train_path + '/pos'):\n",
    "    f = open(train_path + '/pos/' + file, 'r',  encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    train = train.append({'review':text_prep(text), 'class':'pos'}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'aclImdb/test'\n",
    "\n",
    "test = pd.DataFrame(columns=['review', 'class'])\n",
    "for file in os.listdir(test_path + '/neg'):\n",
    "    f = open(test_path + '/neg/' + file, 'r',  encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    test = test.append({'review':text_prep(text), 'class':'neg'}, ignore_index=True)\n",
    "    \n",
    "\n",
    "for file in os.listdir(test_path + '/pos'):\n",
    "    f = open(test_path + '/pos/' + file, 'r',  encoding=\"utf-8\")\n",
    "    text = f.read()\n",
    "    test = test.append({'review':text_prep(text), 'class':'pos'}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-606adc4a5ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "test = test.sample(frac=1).reset_index(drop=True)\n",
    "train_target = train['class'] == 'pos'\n",
    "test_target = train['class'] == 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей с использованием tf-idf векторизации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train['review'], train_target)\n",
    "train_matrix = tfidf.fit_transform(X_train)\n",
    "valid_matrix = tfidf.transform(X_valid)\n",
    "test_matrix = tfidf.transform(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.8970101344985837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(valid_matrix)\n",
    "print('roc-auc ', roc_auc_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.8955734376356823\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(valid_matrix)\n",
    "print('roc-auc ', roc_auc_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6706020691711683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(train_matrix.todense(), y_train)\n",
    "preds = model.predict(valid_matrix.todense())\n",
    "print(roc_auc_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей с использованием Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bag = CountVectorizer()\n",
    "train_matrix = bag.fit_transform(X_train)\n",
    "valid_matrix = bag.transform(X_valid)\n",
    "test_matrix = bag.transform(test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715992371477584\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier()\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(valid_matrix)\n",
    "print(roc_auc_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8644982886615843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(valid_matrix)\n",
    "print(roc_auc_score(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = tfidf.fit_transform(X_train)\n",
    "valid_matrix = tfidf.transform(X_valid)\n",
    "test_matrix = tfidf.transform(test['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Погрешность в оценке моделей с разной векторизацией небольшая, но в данном случае, tf-idf является более точным вариантом, так как текстов достаточно много, чтобы можно было делать поправку на весь набор текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройка гиперпараметров для SVC\n",
    "\n",
    "### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc 0.50408\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc 0.5012\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(penalty='l1', dual=False)\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc 0.5042\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(penalty='l2', loss='hinge')\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=  0.1 , roc-auc  0.5054\n",
      "c=  0.2 , roc-auc  0.50624\n",
      "c=  0.3 , roc-auc  0.5048\n",
      "c=  0.4 , roc-auc  0.50552\n",
      "c=  0.5 , roc-auc  0.50452\n",
      "c=  0.6 , roc-auc  0.50512\n",
      "c=  0.7 , roc-auc  0.5042399999999999\n",
      "c=  0.8 , roc-auc  0.50324\n",
      "c=  0.9 , roc-auc  0.5039199999999999\n"
     ]
    }
   ],
   "source": [
    "for c in np.arange(0.1, 1, 0.1):\n",
    "    model = LinearSVC(penalty='l2', C=c, loss='hinge')\n",
    "    model.fit(train_matrix, y_train)\n",
    "    preds = model.predict(test_matrix)\n",
    "    print('c= ', round(c, 2), ', roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.50624\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(penalty='l2', C=0.2, loss='hinge')\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка гиперпараметров для SGD\n",
    "\n",
    "### L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.50444\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(penalty='l2')\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.50492\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(penalty='l1')\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc-auc  0.50584\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(penalty='elasticnet')\n",
    "model.fit(train_matrix, y_train)\n",
    "preds = model.predict(test_matrix)\n",
    "print('roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio 0.1 , roc-auc  0.50588\n",
      "l1_ratio 0.15 , roc-auc  0.5047200000000001\n",
      "l1_ratio 0.2 , roc-auc  0.50532\n",
      "l1_ratio 0.25 , roc-auc  0.50556\n",
      "l1_ratio 0.3 , roc-auc  0.50456\n",
      "l1_ratio 0.35 , roc-auc  0.50516\n",
      "l1_ratio 0.4 , roc-auc  0.50488\n",
      "l1_ratio 0.45 , roc-auc  0.5042800000000001\n",
      "l1_ratio 0.5 , roc-auc  0.50572\n",
      "l1_ratio 0.55 , roc-auc  0.5056799999999999\n",
      "l1_ratio 0.6 , roc-auc  0.50596\n",
      "l1_ratio 0.65 , roc-auc  0.50588\n",
      "l1_ratio 0.7 , roc-auc  0.50564\n",
      "l1_ratio 0.75 , roc-auc  0.5047200000000001\n",
      "l1_ratio 0.8 , roc-auc  0.50568\n",
      "l1_ratio 0.85 , roc-auc  0.50624\n",
      "l1_ratio 0.9 , roc-auc  0.5065999999999999\n",
      "l1_ratio 0.95 , roc-auc  0.50612\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1, 1, 0.05):\n",
    "    model = SGDClassifier(penalty='elasticnet', l1_ratio=i)\n",
    "    model.fit(train_matrix, y_train)\n",
    "    preds = model.predict(test_matrix)\n",
    "    print('l1_ratio', round(i,2), ', roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат при регуляризации elastic net при l1_ratio = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.0001 , roc-auc  0.5058400000000001\n",
      "alpha 0.00015 , roc-auc  0.50648\n",
      "alpha 0.0002 , roc-auc  0.50632\n",
      "alpha 0.00025 , roc-auc  0.50652\n",
      "alpha 0.0003 , roc-auc  0.50644\n",
      "alpha 0.00035 , roc-auc  0.50628\n",
      "alpha 0.0004 , roc-auc  0.5062\n",
      "alpha 0.00045 , roc-auc  0.50576\n",
      "alpha 0.0005 , roc-auc  0.5044799999999999\n",
      "alpha 0.00055 , roc-auc  0.50464\n",
      "alpha 0.0006 , roc-auc  0.50504\n",
      "alpha 0.00065 , roc-auc  0.5052\n",
      "alpha 0.0007 , roc-auc  0.5064000000000001\n",
      "alpha 0.00075 , roc-auc  0.50624\n",
      "alpha 0.0008 , roc-auc  0.5063200000000001\n",
      "alpha 0.00085 , roc-auc  0.50644\n",
      "alpha 0.0009 , roc-auc  0.50528\n",
      "alpha 0.00095 , roc-auc  0.5059199999999999\n",
      "alpha 0.001 , roc-auc  0.50704\n",
      "alpha 0.00105 , roc-auc  0.5070399999999999\n",
      "alpha 0.0011 , roc-auc  0.5069600000000001\n",
      "alpha 0.00115 , roc-auc  0.50688\n",
      "alpha 0.0012 , roc-auc  0.506\n",
      "alpha 0.00125 , roc-auc  0.50624\n",
      "alpha 0.0013 , roc-auc  0.50664\n",
      "alpha 0.00135 , roc-auc  0.50608\n",
      "alpha 0.0014 , roc-auc  0.50508\n",
      "alpha 0.00145 , roc-auc  0.506\n",
      "alpha 0.0015 , roc-auc  0.5065999999999999\n",
      "alpha 0.00155 , roc-auc  0.50556\n",
      "alpha 0.0016 , roc-auc  0.50504\n",
      "alpha 0.00165 , roc-auc  0.50556\n",
      "alpha 0.0017 , roc-auc  0.50536\n",
      "alpha 0.00175 , roc-auc  0.5042800000000001\n",
      "alpha 0.0018 , roc-auc  0.5052399999999999\n",
      "alpha 0.00185 , roc-auc  0.50508\n",
      "alpha 0.0019 , roc-auc  0.50524\n",
      "alpha 0.00195 , roc-auc  0.5052\n",
      "alpha 0.002 , roc-auc  0.5054799999999999\n",
      "alpha 0.00205 , roc-auc  0.50504\n",
      "alpha 0.0021 , roc-auc  0.5054799999999999\n",
      "alpha 0.00215 , roc-auc  0.50516\n",
      "alpha 0.0022 , roc-auc  0.50504\n",
      "alpha 0.00225 , roc-auc  0.50468\n",
      "alpha 0.0023 , roc-auc  0.50452\n",
      "alpha 0.00235 , roc-auc  0.50512\n",
      "alpha 0.0024 , roc-auc  0.5062\n",
      "alpha 0.00245 , roc-auc  0.50568\n",
      "alpha 0.0025 , roc-auc  0.50572\n",
      "alpha 0.00255 , roc-auc  0.50536\n",
      "alpha 0.0026 , roc-auc  0.50412\n",
      "alpha 0.00265 , roc-auc  0.50552\n",
      "alpha 0.0027 , roc-auc  0.50556\n",
      "alpha 0.00275 , roc-auc  0.50664\n",
      "alpha 0.0028 , roc-auc  0.5052\n",
      "alpha 0.00285 , roc-auc  0.5049199999999999\n",
      "alpha 0.0029 , roc-auc  0.50608\n",
      "alpha 0.00295 , roc-auc  0.5028\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.0001, 0.003, 0.00005):\n",
    "    model = SGDClassifier(penalty='elasticnet', l1_ratio=0.25, alpha=i)\n",
    "    model.fit(train_matrix, y_train)\n",
    "    preds = model.predict(test_matrix)\n",
    "    print('alpha', round(i,6), ', roc-auc ', roc_auc_score(test_target, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оптимальный результат возникает при альфа = 0.00015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
